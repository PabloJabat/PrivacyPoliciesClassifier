{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a Convolutional Neural Network for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed from pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "#Some built-in imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Imports from the repository\n",
    "import data_processing as dp\n",
    "from privacy_policies_dataset import PrivacyPoliciesDataset_all as PPD\n",
    "from cnn import CNN, train_cnn, f1_score, f1_score_per_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read from raw_data all the files and get all the different words we can find within all the files. Both the train and test folders. If we already have a file named dictionary.pkl and read set to True, it will read the dictionary from this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dp.get_tokens(\"raw_data\", read = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load the pretrained embeddings. We will get two python dictionaries. Both have the words as the keys of the python dictionaries and one has the vectors as the keys whilst the other one has the position on the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector_glove, word2idx_glove = dp.get_glove_dicts(\"glove.6B\", 300, read = False)\n",
    "\n",
    "print(\"number of words in the pretrained embeddings: {}\".format(len(word2idx_glove)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the matrix containing all the word embeddings that we will need for the embedding layer of the CNN and we obtain a word2idx of just all the words inside dictionary and not all the words present in the word embeddings. Usually the pretrained embeddings that we will use have more words than what we need, that is the reason why we need to obtain a new word2idx of just all the words that we found in the files inside train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix, word2idx = dp.get_weight_matrix(dictionary, word2vector_glove, 300, read = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the labels that with which we want to perform the classification. We will also show them so that it is clearer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = open(\"labels.pkl\",\"rb\")\n",
    "\n",
    "labels = pickle.load(labels_file)\n",
    "\n",
    "labels_file.close()\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before obtaining the prefectly cleaned data that will be used in the CNN is to aggregate the labels. The dataset provides a files in csv format with repeated sentences. The reason behind this is that some sentences have several labels assigned to them. The last step is to aggregate segments and obtain a list of labels per sentence. The following function gets all the data from raw_data folder and outputs the result in agg_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.aggregate_data(read = False, onefile = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the aggregated data in agg_data we will process all the sentences and transform them into a list of integers. The integers will refer to the position inside the word2idx dictionary. The labels will also be transformed into an n-dimensinal vector with 1s if a sentence has that label and 0s if it doesn't. All the data will be placed in the corresponding folder inside processed_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_matrices_train, labels_matrices_train = dp.process_dataset(\"train\", labels, word2idx, read = False)\n",
    "\n",
    "sentence_matrices_test, labels_matrices_test = dp.process_dataset(\"test\", labels, word2idx, read = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_matrices_all, labels_matrices_all = dp.process_dataset(\"all\", labels, word2idx, read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of Datasets and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an two objects called PrivacyPoliciesDataset containing the training and testing dataset. We will need to resize the sentences/segments as each of them have different number of words. We will fill them with 0s until we have all the sentences/segments of the same length (index 0 refers to a 0 vector). Now that all the sentences have the same length we can group them in a matrix that will be the input for the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PPD(sentence_matrices_all, labels_matrices_all, labels)\n",
    "\n",
    "test_dataset, train_validation_dataset = dataset.split_dataset_randomly()\n",
    "\n",
    "validation_dataset, train_dataset = train_validation_dataset.split_dataset_randomly()\n",
    "\n",
    "test_dataset.pickle_dataset(\"test_dataset.pkl\")\n",
    "\n",
    "train_validation_dataset.pickle_dataset(\"train_validation_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesing train_dataset\n",
    "\n",
    "print(\"Preparing train_dataset --------\")\n",
    "\n",
    "train_dataset = PrivacyPoliciesDataset(\"train\" ,\"raw_data\" , word2idx, labels, read = True)\n",
    "\n",
    "train_dataset.resize_segments()\n",
    "\n",
    "train_dataset.expand_dimensions()\n",
    "\n",
    "train_dataset.group_samples()\n",
    "\n",
    "# Procesing test_dataset\n",
    "\n",
    "print(\"\\n\" + \"Preparing test_dataset  --------\")\n",
    "\n",
    "test_dataset = PrivacyPoliciesDataset(\"test\" ,\"raw_data\" , word2idx, labels, read = True)\n",
    "\n",
    "test_dataset.resize_segments()\n",
    "\n",
    "test_dataset.expand_dimensions()\n",
    "\n",
    "test_dataset.group_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a DataLoader that allows us to use Mini-Batch Gradient descent and we provide the train_dataset as the input along with the size of the batches that we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of CNN and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the 6 main parameters of the CNN we are using:\n",
    "1. Number of words in the dictionary\n",
    "2. Embeddings dimension\n",
    "3. Number of filters per kernel size\n",
    "4. Number of hidden units\n",
    "5. Number of labels to classify\n",
    "6. List of all the kernels sizes we want to use\n",
    "\n",
    "We will also add the pretrained embeddings to the embedding layer of the CNN through load_pretrained_embeddings. The function called train_cn will need two more parameters:\n",
    "1. number of epochs \n",
    "2. learning rate\n",
    "3. momentum constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = CNN(6800, 300, 200, 160, 9, [3])\n",
    "\n",
    "model_all.load_pretrained_embeddings(weights_matrix)\n",
    "\n",
    "epochs, losses = train_cnn(model_all, train_dataloader, epochs_num = 100, lr = 0.025, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the evolution of the Loss with respect to the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses)\n",
    "\n",
    "plt.title(\"loss vs epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save all the parameters used in the CNN (weights of all the layers and the configurations of the CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_all.state_dict(), model_all.cnn_name + \"_state.pt\")\n",
    "\n",
    "model_all.save_cnn_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of the CNN results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the labels true labels from the training and testing data sets and predict the labels using both labels. The predictions are usually refered as y_hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset.labels_list\n",
    "\n",
    "y_test = test_dataset.labels_list\n",
    "\n",
    "y_hat_train = model_all(train_dataset.segments_list)\n",
    "\n",
    "y_hat_test = model_all(test_dataset.segments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show how the F1 score changes for all possible thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_thresholds(y_test, y_hat_test, labels):\n",
    "\n",
    "    threshold_list = np.arange(0.0, 1, 0.01)\n",
    "    \n",
    "    best_f1_label = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    best_t_label = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    for label, index in labels.items():\n",
    "\n",
    "        best_f1 = 0\n",
    "\n",
    "        best_t = 0\n",
    "\n",
    "        for t in threshold_list:\n",
    "\n",
    "            current_f1 = f1_score_per_label(y_test, y_hat_test, t)[0][labels[label]].item()\n",
    "\n",
    "            if current_f1 > best_f1: \n",
    "\n",
    "                best_f1 = current_f1\n",
    "\n",
    "                best_t = t\n",
    "\n",
    "        best_f1_label[index] = best_f1\n",
    "\n",
    "        best_t_label[index] = best_t\n",
    "\n",
    "    return best_f1_label, best_t_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model, train_dataset, test_dataset, labels):\n",
    "\n",
    "    y_train = train_dataset.labels_list\n",
    "\n",
    "    y_test = test_dataset.labels_list\n",
    "    \n",
    "    y_hat_train = model(train_dataset.segments_list)\n",
    "\n",
    "    y_hat_test = model(test_dataset.segments_list)\n",
    "    \n",
    "    # This will be the x axis\n",
    "    threshold_list = np.arange(0.0, 1, 0.01)\n",
    "\n",
    "    # These will be the y axis data\n",
    "    f1_scores_test = [f1_score(y_test, y_hat_test, t)[0] for t in threshold_list]\n",
    "\n",
    "    precisions_test = [f1_score(y_test, y_hat_test, t)[1] for t in threshold_list]\n",
    "\n",
    "    recalls_test = [f1_score(y_test, y_hat_test, t)[2] for t in threshold_list]\n",
    "\n",
    "    f1_scores_train = [f1_score(y_train, y_hat_train, t)[0] for t in threshold_list]\n",
    "\n",
    "    precisions_train =[f1_score(y_train, y_hat_train, t)[1] for t in threshold_list]\n",
    "\n",
    "    recalls_train = [f1_score(y_train, y_hat_train, t)[2] for t in threshold_list]\n",
    "\n",
    "    \"\"\"\n",
    "    Here comes the pyplot code\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "    # We start with the three pyplot axis we want. One for F1, another for precision and one last one for recall\n",
    "    ax_f1 = fig.add_subplot(131)\n",
    "\n",
    "    ax_precision = fig.add_subplot(132)\n",
    "\n",
    "    ax_recall = fig.add_subplot(133)\n",
    "\n",
    "    # We now plot all the data in te corresponding axis\n",
    "    ax_f1.plot(threshold_list, f1_scores_test, label='test')\n",
    "\n",
    "    ax_f1.plot(threshold_list, f1_scores_train, label='train')\n",
    "\n",
    "    ax_f1.set_title('F1 Score vs Threshold')\n",
    "\n",
    "    ax_f1.legend()\n",
    "\n",
    "    ax_precision.plot(threshold_list, precisions_test, label='test')\n",
    "\n",
    "    ax_precision.plot(threshold_list, precisions_train, label='train')\n",
    "\n",
    "    ax_precision.set_title('Precision vs Threshold')\n",
    "\n",
    "    ax_precision.legend()\n",
    "\n",
    "    ax_recall.plot(threshold_list, recalls_test, label='test')\n",
    "\n",
    "    ax_recall.plot(threshold_list, recalls_train, label='train')\n",
    "\n",
    "    ax_recall.set_title('Recall vs Threshold')\n",
    "\n",
    "    ax_recall.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # We show the F1, precision and recall for a threshold of 0.5\n",
    "    f1, precision, recall = f1_score(y_test, y_hat_test, 0.5)\n",
    "\n",
    "    print(\"Scores with 0.5 threshold\")\n",
    "    \n",
    "    print(\"-\" * 35 * 3)\n",
    "    \n",
    "    print(\"f1        |\" + str(f1))\n",
    "\n",
    "    print(\"precision |\" + str(precision))\n",
    "\n",
    "    print(\"recall    |\" + str(recall))\n",
    "    \n",
    "    print(\"-\" * 35 * 3)\n",
    "    \n",
    "    best_f1_label, best_t_label = get_best_thresholds(y_test, y_hat_test, labels)\n",
    "    \n",
    "    print(\"\\n\" + \"F1 Score per Label\")\n",
    "    \n",
    "    print(\"-\" * 35 * 3)\n",
    "    \n",
    "    row_format =\"{:<38}\" * 3\n",
    "    \n",
    "    print(row_format.format(\"Label\", \"F1\", \"Threshold\"))\n",
    "    \n",
    "    print(\"-\" * 35 * 3)\n",
    "    \n",
    "    for label, index in labels.iteritems():\n",
    "        \n",
    "        print row_format.format(label, best_f1_label[index], best_t_label[index])\n",
    "\n",
    "    # We save the figure into a picture\n",
    "    fig.savefig(fname = model.cnn_name + '.png', format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(model_all, train_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following block of code we will find the threshold that with which we obtain the best overall F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_f1_score, best_t_label = get_best_thresholds(y_test, y_hat_test, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show the results for the best combination of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show the F1, precision and recall for the best threshold\n",
    "f1, precision, recall = f1_score(y_test, y_hat_test, torch.tensor(best_t_label))\n",
    "\n",
    "print(\"f1        |\" + str(f1))\n",
    "\n",
    "print(\"precision |\" + str(precision))\n",
    "\n",
    "print(\"recall    |\" + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show how the F1 score changes for all possible thresholds in just one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = np.arange(0.0, 1, 0.01)\n",
    "\n",
    "label = 'User Choice/Control'\n",
    "\n",
    "f1_scores_per_label = [f1_score_per_label(y_test, y_hat_test, t)[0][labels[label]].item() for t in threshold_list]\n",
    "\n",
    "plt.plot(threshold_list, f1_scores_per_label)\n",
    "\n",
    "plt.title(label + \" f1 score\" + \" vs threshold\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f1_label, precision_label, recall_label = f1_score_per_label(y_test, y_hat_test, 0.07)\n",
    "\n",
    "f1_label = f1_label[labels[label]].item()\n",
    "\n",
    "precision_label = precision_label[labels[label]].item()\n",
    "\n",
    "recall_label = recall_label[labels[label]].item()\n",
    "\n",
    "print(\"Label: \" + label + \"\\n\")\n",
    "\n",
    "print(\"f1_label        |\" + str(f1_label))\n",
    "\n",
    "print(\"precision_label |\" + str(precision_label))\n",
    "\n",
    "print(\"recall_label    |\" + str(recall_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2Ks_file = open('cnn_300_200_100_9_[2]__params.pkl', 'rb')\n",
    "\n",
    "params2Ks = pickle.load(params2Ks_file)\n",
    "\n",
    "model_2Ks = CNN(**params2Ks)\n",
    "\n",
    "model_2Ks.load_state_dict(torch.load('cnn_300_200_100_9_[2]__state.pt'))\n",
    "\n",
    "model_results(model_2Ks, train_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3Ks_file = open('cnn_300_200_100_9_[3]__params.pkl', 'rb')\n",
    "\n",
    "params3Ks = pickle.load(params3Ks_file)\n",
    "\n",
    "model_3Ks = CNN(**params3Ks)\n",
    "\n",
    "model_3Ks.load_state_dict(torch.load('cnn_300_200_100_9_[3]__state.pt'))\n",
    "\n",
    "model_results(model_3Ks, train_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params5Ks_file = open('cnn_300_200_100_9_[5]__params.pkl', 'rb')\n",
    "\n",
    "params5Ks = pickle.load(params5Ks_file)\n",
    "\n",
    "model_5Ks = CNN(**params5Ks)\n",
    "\n",
    "model_5Ks.load_state_dict(torch.load('cnn_300_200_100_9_[5]__state.pt'))\n",
    "\n",
    "model_results(model_5Ks, train_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params7Ks_file = open('cnn_300_200_100_9_[7]__params.pkl', 'rb')\n",
    "\n",
    "params7Ks = pickle.load(params7Ks_file)\n",
    "\n",
    "model_7Ks = CNN(**params7Ks)\n",
    "\n",
    "model_7Ks.load_state_dict(torch.load('cnn_300_200_100_9_[7]__state.pt'))\n",
    "\n",
    "model_results(model_7Ks, train_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to take into consideration\n",
    "\n",
    "1. It seems that with the Globe pretrained embeddings there are 1000 words that are missing and are initialized as random vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
