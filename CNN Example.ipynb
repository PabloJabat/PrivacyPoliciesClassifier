{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a Convolutional Neural Network for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed from pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#Some built-in imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from os.path import join\n",
    "\n",
    "#Imports from the repository\n",
    "import data_processing as dp\n",
    "from privacy_policies_dataset import PrivacyPoliciesDataset_all as PPD\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating word embeddings matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read from raw_data all the files and get all the different words we can find within all the files. If we already have a file named dictionary.pkl and read set to True, it will read the dictionary from this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dp.get_tokens(\"raw_data\", \"embeddings_data\", read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load the pretrained embeddings. We will get two python dictionaries. Both have the words as the keys of the python dictionaries and one has the vectors as the keys whilst the other one has the position on the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vector_glove = dp.get_glove_dicts(\"glove.6B\", \"embeddings_data\", 300, read = True)\n",
    "\n",
    "print(\"Number of words in the pretrained embeddings: {}\".format(len(word2vector_glove)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the matrix containing all the word embeddings that we will need for the embedding layer of the CNN and we obtain a word2idx of just all the words inside dictionary and not all the words present in the word embeddings. Usually the pretrained embeddings that we will use have more words than what we need, that is the reason why we need to obtain a new word2idx of just all the words that we found in the files inside train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix, word2idx = dp.get_weight_matrix(dictionary, word2vector_glove, 300, \"embeddings_data\", read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step before obtaining the prefectly cleaned data that will be used in the CNN is to aggregate the labels. The raw_data folder provides a series of files in csv format with repeated sentences. The reason behind this is that some sentences have several labels assigned to them. The last step is to aggregate segments and obtain a list of labels per sentence. The following function gets all the data from raw_data folder and outputs the result in agg_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.aggregate_data(read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the aggregated data in agg_data we will process all the sentences and transform them into a list of integers. The integers will refer to the position inside the word2idx dictionary. The labels will also be transformed into an n-dimensinal vector with 1s if a sentence has that label and 0s if it doesn't. All the data will be placed in the corresponding folder inside processed_data. We load the labels with which we want to perform the classification. We will also show them so that it is clearer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = open(\"labels.pkl\",\"rb\")\n",
    "\n",
    "labels = pickle.load(labels_file)\n",
    "\n",
    "labels_file.close()\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_matrices_all, labels_matrices_all = dp.process_dataset(labels, word2idx, read = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create an PPD which stands for PrivacyPoliciesDataset containing the training and testing dataset. We will need to split the data in two to get the test training data and the data that will be used for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PPD(sentence_matrices_all, labels_matrices_all, labels)\n",
    "\n",
    "test_dataset, train_validation_dataset = dataset.split_dataset_randomly()\n",
    "\n",
    "validation_dataset, train_dataset = train_validation_dataset.split_dataset_randomly()\n",
    "\n",
    "test_dataset.pickle_dataset(\"datasets/test_dataset.pkl\")\n",
    "\n",
    "train_validation_dataset.pickle_dataset(\"datasets/train_validation_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we aready had all the data split and prepared we can load it like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PPD.unpickle_dataset(\"datasets/test_dataset.pkl\")\n",
    "\n",
    "train_validation_dataset = PPD.unpickle_dataset(\"datasets/train_validation_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of CNN and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the 6 main parameters of the CNN we are using:\n",
    "1. Number of words in the dictionary\n",
    "2. Embeddings dimension\n",
    "3. Number of filters per kernel size\n",
    "4. Number of hidden units\n",
    "5. Number of labels to classify\n",
    "6. List of all the kernels sizes we want to use\n",
    "7. Name of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(6800, 300, 200, 100, 9, [3], name='bis')\n",
    "\n",
    "model.load_pretrained_embeddings(weights_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add the pretrained embeddings to the embedding layer of the CNN through load_pretrained_embeddings. The function called train_cn will need two more parameters:\n",
    "1. number of epochs \n",
    "2. learning rate\n",
    "3. momentum constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.train_cnn(train_validation_dataset, epochs_num = 50, lr = 0.01, momentum = 0.9)\n",
    "\n",
    "epochs, train_losses, validation_losses = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the evolution of the Loss with respect to the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_losses, label = \"train\")\n",
    "\n",
    "plt.plot(epochs, validation_losses, label = \"validation\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"loss vs epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save all the parameters used in the CNN (weights of all the layers and the configurations of the CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = join(\"trained_models\", model.cnn_name + \"_state.pt\")\n",
    "\n",
    "torch.save(model.state_dict(), dict_path)\n",
    "\n",
    "model.save_cnn_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of the CNN results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the labels true labels from the training and testing data sets and predict the labels using both labels. The predictions are usually refered as y_hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_validation_dataset.labels_tensor\n",
    "\n",
    "y_test = test_dataset.labels_tensor\n",
    "\n",
    "x_train = PPD.collate_data(train_validation_dataset)[0]\n",
    "\n",
    "x_test = PPD.collate_data(test_dataset)[0]\n",
    "\n",
    "y_hat_train = model(x_train)\n",
    "\n",
    "y_hat_test = model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show how the F1 score changes for all possible thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_results(train_validation_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following block of code we will find the threshold that with which we obtain the best overall F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_f1_score, best_t_label = CNN.get_best_thresholds(y_train, y_hat_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show the results for the best combination of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show the F1, precision and recall for the best threshold\n",
    "f1, precision, recall = CNN.f1_score(y_test, y_hat_test, torch.tensor(best_t_label))\n",
    "\n",
    "print(\"f1        |\" + str(f1))\n",
    "\n",
    "print(\"precision |\" + str(precision))\n",
    "\n",
    "print(\"recall    |\" + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show a list of all the possible labels to remind the user which ones are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, i in labels.iteritems():\n",
    "    \n",
    "    print(\"index {}. {}.\".format(i, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show how the F1 score changes for all possible thresholds in just one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = np.arange(0.0, 1, 0.01)\n",
    "\n",
    "label = 'User Choice/Control'\n",
    "\n",
    "f1_scores_per_label = [CNN.f1_score_per_label(y_test, y_hat_test, t)[0][labels[label]].item() for t in threshold_list]\n",
    "\n",
    "plt.plot(threshold_list, f1_scores_per_label)\n",
    "\n",
    "plt.title(label + \" f1 score\" + \" vs threshold\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f1_label, precision_label, recall_label = CNN.f1_score_per_label(y_test, y_hat_test, 0.5)\n",
    "\n",
    "f1_label = f1_label[labels[label]].item()\n",
    "\n",
    "precision_label = precision_label[labels[label]].item()\n",
    "\n",
    "recall_label = recall_label[labels[label]].item()\n",
    "\n",
    "print(\"Label: \" + label + \"\\n\")\n",
    "\n",
    "print(\"f1_label        |\" + str(f1_label))\n",
    "\n",
    "print(\"precision_label |\" + str(precision_label))\n",
    "\n",
    "print(\"recall_label    |\" + str(recall_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2Ks_file = open('trained_models/cnn_300_200_100_9_[2]__params.pkl', 'rb')\n",
    "\n",
    "params2Ks = pickle.load(params2Ks_file)\n",
    "\n",
    "model_2Ks = CNN(**params2Ks)\n",
    "\n",
    "model_2Ks.load_state_dict(torch.load('trained_models/cnn_300_200_100_9_[2]__state.pt'))\n",
    "\n",
    "model_2Ks.print_results(train_validation_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3Ks_file = open('trained_models/cnn_300_200_100_9_[3]__params.pkl', 'rb')\n",
    "\n",
    "params3Ks = pickle.load(params3Ks_file)\n",
    "\n",
    "model_3Ks = CNN(**params3Ks)\n",
    "\n",
    "model_3Ks.load_state_dict(torch.load('trained_models/cnn_300_200_100_9_[3]__state.pt'))\n",
    "\n",
    "model_3Ks.print_results(train_validation_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params5Ks_file = open('trained_models/cnn_300_200_100_9_[5]__params.pkl', 'rb')\n",
    "\n",
    "params5Ks = pickle.load(params5Ks_file)\n",
    "\n",
    "model_5Ks = CNN(**params5Ks)\n",
    "\n",
    "model_5Ks.load_state_dict(torch.load('trained_models/cnn_300_200_100_9_[5]__state.pt'))\n",
    "\n",
    "model_5Ks.print_results(train_validation_dataset, test_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params7Ks_file = open('trained_models/cnn_300_200_100_9_[7]__params.pkl', 'rb')\n",
    "\n",
    "params7Ks = pickle.load(params7Ks_file)\n",
    "\n",
    "model_7Ks = CNN(**params7Ks)\n",
    "\n",
    "model_7Ks.load_state_dict(torch.load('trained_models/cnn_300_200_100_9_[7]__state.pt'))\n",
    "\n",
    "model_7Ks.print_results(train_validation_dataset, test_dataset, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
