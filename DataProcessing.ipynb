{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, log10\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import data_processing as dp\n",
    "import pickle\n",
    "from privacy_policies_dataset import PrivacyPoliciesDataset\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from cnn import CNN, train_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "dictionary = dp.get_tokens(\"raw_data\", read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from files word2vector.pkl and word2idx.pkl\n"
     ]
    }
   ],
   "source": [
    "word2vector, word2idx_glove = dp.get_glove_dicts(\"glove.6B\", 100, read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absent_words(dictionary, word2vector):\n",
    "\n",
    "    absent_words = []\n",
    "\n",
    "    for word in dictionary:\n",
    "\n",
    "        try:\n",
    "\n",
    "            word2vector[word]\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            absent_words.append(word)\n",
    "            \n",
    "    return absent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file weights_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "weights_matrix, word2idx = dp.get_weight_matrix(dictionary, word2vector, 100, read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = open(\"labels.pkl\",\"rb\")\n",
    "\n",
    "labels = pickle.load(labels_file)\n",
    "\n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n"
     ]
    }
   ],
   "source": [
    "dp.aggregate_data(read = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed_data/\n"
     ]
    }
   ],
   "source": [
    "sentence_matrices_train, labels_matrices_train = dp.process_dataset(\"train\", labels, word2idx, read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed_data/\n"
     ]
    }
   ],
   "source": [
    "sentence_matrices_test, labels_matrices_test = dp.process_dataset(\"test\", labels, word2idx, read = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed_data/\n",
      "Resizing segments (filling with zeros). Target size: 425\n",
      "Grouping samples into one Tensor\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PrivacyPoliciesDataset(\"train\" ,\"raw_data\", word2idx, labels, read = True)\n",
    "\n",
    "train_dataset.resize_segments()\n",
    "\n",
    "train_dataset.expand_dimensions()\n",
    "\n",
    "train_dataset.group_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2851, 1, 425])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.segments_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2851, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from processed_data/\n",
      "Resizing segments (filling with zeros). Target size: 387\n",
      "Grouping samples into one Tensor\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PrivacyPoliciesDataset(\"test\" ,\"raw_data\", word2idx, labels, read = True)\n",
    "\n",
    "test_dataset.resize_segments()\n",
    "\n",
    "test_dataset.expand_dimensions()\n",
    "\n",
    "test_dataset.group_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([875, 1, 387])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.segments_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([875, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = CNN(6800, 100, 12, 22, 9, [3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all.load_embeddings(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0425,  0.3873, -0.6664,  ..., -1.4347, -0.2803,  0.5186],\n",
       "        [ 0.0515, -0.1108, -0.1030,  ...,  1.1112,  0.0970,  0.5142],\n",
       "        ...,\n",
       "        [-0.1834,  0.4438, -0.0218,  ...,  0.0879, -0.1629,  1.1347],\n",
       "        [-0.3543,  0.2249, -0.2998,  ..., -0.3188,  0.5824, -0.6919],\n",
       "        [ 0.3140, -0.4960, -0.3450,  ...,  0.3828,  0.3620,  0.4923]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 1 -- progress: 100% -- time: 0.383099438015 mins\n",
      "Training completed. Total training time: 0.3 mins\n"
     ]
    }
   ],
   "source": [
    "epochs, losses = train_cnn(model_all, train_dataloader, epochs_num = 2, lr = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses)\n",
    "\n",
    "plt.title(\"loss vs epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_all.state_dict(),\"model_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all.save_cnn_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset.labels_list\n",
    "\n",
    "y_test = test_dataset.labels_list\n",
    "\n",
    "y_hat_train = model_all(train_dataset.segments_list)\n",
    "\n",
    "y_hat_test = model_all(test_dataset.segments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = torch.tensor([0.08, 0.005, 0.33, 0.45, 0.5, 0.24, 0.02, 0.64, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred, threshold, dim = 0, eps = 1e-9):\n",
    "\n",
    "    y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    \n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum(dim = dim)\n",
    "    \n",
    "    precision = true_positive.div(y_pred.sum(dim = dim).add(eps))\n",
    "    \n",
    "    recall = true_positive.div(y_true.sum(dim = dim).add(eps))\n",
    "    \n",
    "    f1 = torch.mean((precision * recall).div(precision + recall + eps) * 2)\n",
    "\n",
    "    return f1.item(), torch.mean(precision).item(), torch.mean(recall).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_hat_test, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_per_label(y_true, y_pred, threshold, dim=0, eps=1e-9):\n",
    "\n",
    "    y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    \n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum(dim=dim)\n",
    "    \n",
    "    precision = true_positive.div(y_pred.sum(dim=dim).add(eps))\n",
    "    \n",
    "    recall = true_positive.div(y_true.sum(dim=dim).add(eps))\n",
    "    \n",
    "    f1 = (precision * recall).div(precision + recall + eps) * 2\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(Y, Y_hat, test = 'ALO', **kwargs):\n",
    "\n",
    "    def at_least_one(y, y_hat, threshold = 0.5):\n",
    "        \n",
    "        y_hat = y_hat > threshold\n",
    "    \n",
    "        return any([y_i.item() and y_hat_i.item() for y_i, y_hat_i in zip(y, y_hat)])\n",
    "    \n",
    "    def most_probable_label(y, y_hat):\n",
    "\n",
    "        i_ = [i for i, a in enumerate(y) if a == max(y)]\n",
    "\n",
    "        [j_] = [j for j, b in enumerate(y_hat) if b == max(y_hat)]\n",
    "        \n",
    "        return j_ in i_\n",
    "    \n",
    "    num_samples = float(Y.shape[0])\n",
    "    \n",
    "    iterations = 0\n",
    "    \n",
    "    if test == 'ALO':\n",
    "        \n",
    "        parameters = dict(kwargs)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            positives = sum([at_least_one(y, y_hat, parameters['threshold']) for y, y_hat in zip(Y, Y_hat)])\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            positives = sum([at_least_one(y, y_hat) for y, y_hat in zip(Y, Y_hat)])      \n",
    "        \n",
    "    elif test == 'MPL':\n",
    "        \n",
    "        positives = sum([most_probable_label(y, y_hat) for y, y_hat in zip(Y, Y_hat)])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"not a valid test name ...\")\n",
    "        \n",
    "        positives = 0\n",
    "    \n",
    "    return positives / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = np.arange(0.0, 1, 0.01)\n",
    "\n",
    "f1_scores = [f1_score(y_test, y_hat_test, t)[0] for t in threshold_list]\n",
    "\n",
    "plt.plot(threshold_list, f1_scores)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, precision, recall = f1_score(y_hat_test, y_hat_test, 0.25)\n",
    "\n",
    "print(\"f1        |\" + str(f1))\n",
    "\n",
    "print(\"precision |\" + str(precision))\n",
    "\n",
    "print(\"recall    |\" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = np.arange(0.0, 1, 0.01)\n",
    "\n",
    "label = 'User Choice/Control'\n",
    "\n",
    "f1_scores_per_label = [f1_score_per_label(y_test, y_hat_test, t)[0][labels[label]].item() for t in threshold_list]\n",
    "\n",
    "plt.plot(threshold_list, f1_scores_per_label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_per_label(y_test, y_hat_test, 0.01)[0][labels[label]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"second_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to take into consideration\n",
    "\n",
    "1. It seems that with teh GloVe pretrained embeddings there are 1000 words that are missing and are initialized as random vectors.\n",
    "2. Here we can see a very strange behaviour. We are expecting to have all 0s except for the last entry in which we are expecting Ln(0.9) and it is not even close to it. It seems they are not computing the BCE exactly as we think."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
