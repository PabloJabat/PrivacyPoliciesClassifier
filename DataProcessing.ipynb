{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import log, log10\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import data_processing as dp\n",
    "import pickle\n",
    "from privacy_policies_dataset import PrivacyPoliciesDataset\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dp.get_tokens(\"raw_data\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector, word2idx_glove = dp.get_glove_dicts(\"glove.6B\", 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix, word2idx = dp.get_weight_matrix(dictionary, word2vector, 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = open(\"labels.pkl\",\"rb\")\n",
    "\n",
    "labels = pickle.load(labels_file)\n",
    "\n",
    "labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_matrices, labels_matrices = dp.process_dataset(labels, word2idx, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.aggregate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PrivacyPoliciesDataset(\"raw_data\", word2idx, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.resize_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.segments_list[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.expand_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.group_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.segments_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.labels_list.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myemb = nn.Embedding.from_pretrained(torch.tensor(weights_matrix))\n",
    "\n",
    "myemb.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = myemb(dataset.segments_list)\n",
    "\n",
    "print(\"Before reshaping: \" + str(matrix.shape))\n",
    "\n",
    "# matrix = matrix.view(1,1,67,50)\n",
    "\n",
    "# print(\"After reshaping: \" + str(matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, weights_matrix, Co, C, Ks):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        num_embeddings, embeddings_dim = weights_matrix.shape\n",
    "        \n",
    "        self.Co = Co\n",
    "        \n",
    "        self.C = C\n",
    "        \n",
    "        self.Ks = Ks\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights_matrix).float())       \n",
    "                       \n",
    "        self.convolutions = nn.ModuleList([nn.Conv2d(1,self.Co,(k, embeddings_dim)) for k in Ks])\n",
    "            \n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "        #self.max_pool = torch.max\n",
    "        \n",
    "        self.linear = nn.Linear(self.Co * len(self.Ks), self.C)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = [self.relu(conv(x)).squeeze(3) for conv in self.convolutions]\n",
    "        \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        \n",
    "        x = torch.cat(x,1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(weights_matrix, 6, 10, [3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = dataset.segments_list\n",
    "g\n",
    "target = dataset.labels_list.float()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    output = model(input)\n",
    "    \n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        \n",
    "        print(\"loss: \" + str(loss))\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[2].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"first_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to take into consideration\n",
    "\n",
    "1. It seems that with teh GloVe pretrained embeddings there are 1000 words that are missing and are initialized as random vectors.\n",
    "2. Here we can see a very strange behaviour. We are expecting to have all 0s except for the last entry in which we are expecting Ln(0.9) and it is not even close to it. It seems they are not computing the BCE exactly as we think."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
